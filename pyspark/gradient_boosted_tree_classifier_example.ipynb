{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#\n",
        "# Licensed to the Apache Software Foundation (ASF) under one or more\n",
        "# contributor license agreements.  See the NOTICE file distributed with\n",
        "# this work for additional information regarding copyright ownership.\n",
        "# The ASF licenses this file to You under the Apache License, Version 2.0\n",
        "# (the \"License\"); you may not use this file except in compliance with\n",
        "# the License.  You may obtain a copy of the License at\n",
        "#\n",
        "#    http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "#\n",
        "\n",
        "\"\"\"\n",
        "Gradient Boosted Tree Classifier Example.\n",
        "\"\"\"\n",
        "from __future__ import print_function\n",
        "\n",
        "# $example on$\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# $example off$\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    spark = SparkSession\\\n",
        "        .builder\\\n",
        "        .appName(\"GradientBoostedTreeClassifierExample\")\\\n",
        "        .getOrCreate()\n",
        "\n",
        "    # $example on$\n",
        "    # Load and parse the data file, converting it to a DataFrame.\n",
        "    data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
        "\n",
        "    # Index labels, adding metadata to the label column.\n",
        "    # Fit on whole dataset to include all labels in index.\n",
        "    labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
        "    # Automatically identify categorical features, and index them.\n",
        "    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "    featureIndexer =\\\n",
        "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
        "\n",
        "    # Split the data into training and test sets (30% held out for testing)\n",
        "    (trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "    # Train a GBT model.\n",
        "    gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
        "\n",
        "    # Chain indexers and GBT in a Pipeline\n",
        "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
        "\n",
        "    # Train model.  This also runs the indexers.\n",
        "    model = pipeline.fit(trainingData)\n",
        "\n",
        "    # Make predictions.\n",
        "    predictions = model.transform(testData)\n",
        "\n",
        "    # Select example rows to display.\n",
        "    predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
        "\n",
        "    # Select (prediction, true label) and compute test error\n",
        "    evaluator = MulticlassClassificationEvaluator(\n",
        "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "\n",
        "    gbtModel = model.stages[2]\n",
        "    print(gbtModel)  # summary only\n",
        "    # $example off$\n",
        "\n",
        "    spark.stop()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}